{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcuOm5Idz7XV",
    "outputId": "99f6c8a5-cc33-4d25-edb6-5600b7cf304b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/474.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
      "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting langchain\n",
      "  Downloading langchain-0.0.343-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-core<0.1,>=0.0.7 (from langchain)\n",
      "  Downloading langchain_core-0.0.7-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Downloading langsmith-0.0.67-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.19.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (67.7.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (0.41.3)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.27.7)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (17.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n",
      "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.343 langchain-core-0.0.7 langsmith-0.0.67 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Collecting rapidocr-onnxruntime\n",
      "  Downloading rapidocr_onnxruntime-1.3.8-py3-none-any.whl (14.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
      "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.7.0 (from rapidocr-onnxruntime)\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.23.5)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
      "Requirement already satisfied: Shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (6.0.1)\n",
      "Requirement already satisfied: Pillow<=9.5.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (9.4.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (4.25.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
      "Installing collected packages: pyclipper, humanfriendly, coloredlogs, onnxruntime, rapidocr-onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.3 pyclipper-1.3.0.post5 rapidocr-onnxruntime-1.3.8\n",
      "Collecting ctransformers\n",
      "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.19.4)\n",
      "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.7.22)\n",
      "Installing collected packages: ctransformers\n",
      "Successfully installed ctransformers-0.2.27\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.11.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.3)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2023.6.15-py3-none-any.whl (275 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.1/275.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.23.5)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.5.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=0924350a31ab58d60a610709fa83fa6171002919d9fa0e9cc8a508ebe119eeb7\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, langdetect, emoji, backoff, unstructured\n",
      "Successfully installed backoff-2.2.1 emoji-2.8.0 filetype-1.2.0 langdetect-1.0.9 python-iso639-2023.6.15 python-magic-0.4.27 rapidfuzz-3.5.2 unstructured-0.11.2\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "!pip install -qU datasets==2.12.0 qdrant-client==1.2.0 sentence-transformers==2.2.2 torch==2.0.1\n",
    "!pip install langchain sentence_transformers\n",
    "!pip install rapidocr-onnxruntime\n",
    "# !pip install pypdf\n",
    "!pip install ctransformers\n",
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "buXeBCcl1nsB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/QnA/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings#to get embeddings\n",
    "from langchain.vectorstores import Qdrant #vector database\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.llms import CTransformers#to get llm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter#splitting text into chunks\n",
    "from langchain.chains import RetrievalQA#building Retrieval chain\n",
    "# from langchain.document_loaders import PyPDFLoader,  UnstructuredURLLoader #to read pdfs, urls\n",
    "import torch\n",
    "# from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9GzmoIjW-MvY"
   },
   "outputs": [],
   "source": [
    "def create_description_and_metadata(row):\n",
    "    # Create description\n",
    "    description = f\"The product {row['product']} belongs to the category {row['category']} and subcategory {row['sub_category']}, manufactured by the brand {row['brand']}. It is priced at {row['sale_price']}, with a market price of {row['market_price']}. This product is of type {row['type']} and has a rating of {row['rating']}. Description: {row['description']}.\"\n",
    "\n",
    "    # Create metadata\n",
    "    metadata = {\n",
    "        'name': row['product'],\n",
    "        'category': row['category'],\n",
    "        'sub_category': row['sub_category'],\n",
    "        'brand': row['brand'],\n",
    "        'sale_price': row['sale_price'],\n",
    "        'market_price': row['market_price'],\n",
    "        'type': row['type'],\n",
    "        'rating': row['rating'],\n",
    "        'decription' : row['description']\n",
    "    }\n",
    "\n",
    "    return description, metadata\n",
    "\n",
    "# Set the file path\n",
    "project_path = '/home/akash/Documents/Context-QnA/'\n",
    "filepath = project_path + 'bigBasketProducts.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# Apply the create_description_and_metadata function to each row\n",
    "df[['description', 'metadata']] = df.apply(create_description_and_metadata, axis=1, result_type='expand')\n",
    "\n",
    "# Extract metadata list and save to a text file\n",
    "metadata_list = df['metadata'].tolist()\n",
    "\n",
    "with open(project_path + 'bigBasketProducts_metadata_list.txt', 'w') as f:\n",
    "    for metadata in metadata_list:\n",
    "        f.write(str(metadata) + '\\n')\n",
    "\n",
    "# Keep only the 'description' column\n",
    "df = df[['description']]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(project_path + 'dataset.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ev5iRl1EPcxW",
    "outputId": "52c4271d-4854-4b23-f8ad-1cf2d9e2fbd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The product Garlic Oil - Vegetarian Capsule 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The product Water Bottle - Orange belongs to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The product Brass Angle Deep - Plain, No.2 bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The product Cereal Flip Lid Container/Storage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The product Creme Soft Soap - For Hands &amp; Body...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  The product Garlic Oil - Vegetarian Capsule 50...\n",
       "1  The product Water Bottle - Orange belongs to t...\n",
       "2  The product Brass Angle Deep - Plain, No.2 bel...\n",
       "3  The product Cereal Flip Lid Container/Storage ...\n",
       "4  The product Creme Soft Soap - For Hands & Body..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF4IC-bvPh-O",
    "outputId": "c49e816f-374d-45a0-9eab-1389acc3b1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Garlic Oil - Vegetarian Capsule 500 mg', 'category': 'Beauty & Hygiene', 'sub_category': 'Hair Care', 'brand': 'Sri Sri Ayurveda ', 'sale_price': 220.0, 'market_price': 220.0, 'type': 'Hair Oil & Serum', 'rating': 4.1, 'decription': 'This Product contains Garlic Oil that is known to help proper digestion, maintain proper cholesterol levels, support cardiovascular and also build immunity.  For Beauty tips, tricks & more visit https://bigbasket.blog/'}\n"
     ]
    }
   ],
   "source": [
    "# metadata = metadata_list\n",
    "# print(metadata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WdnBXnCeflKk"
   },
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YNlV1C8lflVq"
   },
   "outputs": [],
   "source": [
    "# set device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "# retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\n",
    "# retriever\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "efot2bayYP25"
   },
   "outputs": [],
   "source": [
    "collections = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5KxTt5RflQ1",
    "outputId": "c01d99c2-b505-4d5e-a9f1-ffe3b535fa3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[]\n",
      "collections=[CollectionDescription(name='BigBasket-QnA')]\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"BigBasket-QnA\"\n",
    "\n",
    "collections = client.get_collections()\n",
    "print(collections)\n",
    "\n",
    "# only create collection if it doesn't exist\n",
    "if collection_name not in [c.name for c in collections.collections]:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "collections = client.get_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d06NpQMbiJx3"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPMkKDLcFgQb",
    "outputId": "b46f246f-0f06-40c3-a65a-4c8bf3de2325"
   },
   "outputs": [],
   "source": [
    "print(metadata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UnBoKrHkiOeu",
    "outputId": "57c95d39-26c8-4b55-e885-91bdfab8111e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8347a4af-92da-4bf9-a23e-7718000bd74e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The product Garlic Oil - Vegetarian Capsule 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The product Water Bottle - Orange belongs to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The product Brass Angle Deep - Plain, No.2 bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The product Cereal Flip Lid Container/Storage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The product Creme Soft Soap - For Hands &amp; Body...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8347a4af-92da-4bf9-a23e-7718000bd74e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8347a4af-92da-4bf9-a23e-7718000bd74e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8347a4af-92da-4bf9-a23e-7718000bd74e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a718673b-75d3-4830-8933-406262536b55\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a718673b-75d3-4830-8933-406262536b55')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a718673b-75d3-4830-8933-406262536b55 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                         description\n",
       "0  The product Garlic Oil - Vegetarian Capsule 50...\n",
       "1  The product Water Bottle - Orange belongs to t...\n",
       "2  The product Brass Angle Deep - Plain, No.2 bel...\n",
       "3  The product Cereal Flip Lid Container/Storage ...\n",
       "4  The product Creme Soft Soap - For Hands & Body..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "248ed5b0fc2e4a79b16077ebd9ff8271",
      "2496104b44804729890b9bb8e97ecb8f",
      "b1ca4ae79288443781ab656986cb07b4",
      "6487943299394b3c8963ef2bb09b5429",
      "1305681bdaf54a9980d83b741c6f80ca",
      "83a023425d2047eba31d6e891f7bb67d",
      "9e8a4ea798e04d78bd2b8eaed2d5768b",
      "ec72171ba64940d4b3de4fa7fdc4191d",
      "c9e7108c96d04230a92208d5a9b01498",
      "31792a1173b84e44ab6354cb90393254",
      "8a38a7e2a6814e9e9839f1c87f05b8b4"
     ]
    },
    "id": "6IZ3xwLSflZ2",
    "outputId": "b921667a-0914-4798-a9b0-78894bfc07a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████▌   | 99/108 [15:13<01:32, 10.26s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 256  # specify batch size according to your RAM and compute, higher batch size = more RAM usage\n",
    "\n",
    "for index in tqdm(range(0, len(df), batch_size)):\n",
    "    i_end = min(index + batch_size, len(df))  # find end of batch\n",
    "    batch = df.iloc[index:i_end]  # extract batch\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "    emb = embeddings.embed_documents(batch[\"description\"]) # generate embeddings for batch\n",
    "    meta = metadata[index:i_end]\n",
    "\n",
    "    ids = list(range(index, i_end))  # create unique IDs\n",
    "\n",
    "    # upsert to qdrant\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=models.Batch(ids=ids, vectors=emb, payloads=meta),\n",
    "    )\n",
    "\n",
    "collection_vector_count = client.get_collection(collection_name=collection_name).vectors_count\n",
    "print(f\"Vector count in collection: {collection_vector_count}\")\n",
    "assert collection_vector_count == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAS99YGjmsjl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPY1A2Y6fleP"
   },
   "outputs": [],
   "source": [
    "# snapshot_info = client.create_snapshot(collection_name=collection_name)\n",
    "# print(snapshot_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgYFP8Bnflm4"
   },
   "outputs": [],
   "source": [
    "# client.upload_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors=emb,\n",
    "#     batch_size=64,\n",
    "#     parallel=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SIbC7YXcpVX0"
   },
   "outputs": [],
   "source": [
    "sentencetf = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vVx_WZz389al"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWoUHXjsCrD7"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K96AD5Qw1n44"
   },
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    llm = CTransformers(\n",
    "        model = \"TheBloke/Llama-2-7B-Chat-GGML\",\n",
    "        model_type=\"llama\",\n",
    "        temperature = 0.2\n",
    "        )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "34fb99e015e447b7a620c31f44be09e8",
      "1c68cf2ce64d4c46ae4099d5be042868",
      "cbbccd3f802f40ff80efb03b95633e43",
      "d1813de27ff64e0eabd2669e9a439e55",
      "df87ce4831d548b1905fa4adbcc5a60e",
      "fc4ad43b92b54945b680eee32f3892fd",
      "46dd3e5fb01746e69e4b31fa9c16ec92",
      "b49e3abf561246d380a3458e5f47933a",
      "1208e34b755c452bad18f4c75e539d53",
      "c8d6fc0406fe4258a5a28cd26875d432",
      "a9f6bf5f2ec84833961ebe432c2a47ad",
      "81913db5c5434f82aaf31e3a66538684",
      "0f12c9e61304449da5682ed238e5daac",
      "96ddfebe6180454e96973604e3671f0f",
      "8f7edb1fd1254ac88ab2f40227f623bc",
      "88ef181331764920938918ada29925ec",
      "bd2f061e1d8743698d0c1f95514ca516",
      "6e0d1e97b73c4d55aeab511820cd8f0b",
      "0aac17a0cae54c9db845ff5de218f9ab",
      "35a3b06ff02b4284ab83bd1d35295b1f",
      "92e47a29f21e44409947450846be8c8b",
      "53141e486281440a8f88794f289f3f38"
     ]
    },
    "id": "n88S4pJ39Dfc",
    "outputId": "4460b546-7cf2-41a3-fb77-75f372958114"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files:   0%|                                   | 0/1 [00:00<?, ?it/s]\n",
      "config.json: 100%|███████████████████████████| 29.0/29.0 [00:00<00:00, 5.95kB/s]\u001b[A\n",
      "Fetching 1 files: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Fetching 1 files:   0%|                                   | 0/1 [00:00<?, ?it/s]\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   0%|              | 0.00/2.87G [00:00<?, ?B/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   0%|     | 10.5M/2.87G [00:01<04:34, 10.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   1%|     | 21.0M/2.87G [00:01<03:38, 13.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   1%|     | 31.5M/2.87G [00:02<03:14, 14.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   1%|     | 41.9M/2.87G [00:03<03:30, 13.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   2%|     | 52.4M/2.87G [00:03<03:21, 14.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   2%|     | 62.9M/2.87G [00:04<03:09, 14.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   3%|▏    | 73.4M/2.87G [00:05<03:21, 13.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   3%|▏    | 83.9M/2.87G [00:05<03:09, 14.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   3%|▏    | 94.4M/2.87G [00:06<03:10, 14.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   4%|▏     | 105M/2.87G [00:07<03:07, 14.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   4%|▏     | 115M/2.87G [00:08<03:01, 15.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   4%|▎     | 126M/2.87G [00:08<02:56, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   5%|▎     | 136M/2.87G [00:09<02:56, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   5%|▎     | 147M/2.87G [00:10<03:01, 14.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   5%|▎     | 157M/2.87G [00:11<03:18, 13.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   6%|▎     | 168M/2.87G [00:11<03:15, 13.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   6%|▎     | 178M/2.87G [00:12<03:12, 14.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   7%|▍     | 189M/2.87G [00:13<03:08, 14.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   7%|▍     | 199M/2.87G [00:13<03:06, 14.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   7%|▍     | 210M/2.87G [00:16<04:55, 8.99MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   8%|▍     | 220M/2.87G [00:16<04:22, 10.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   8%|▍     | 231M/2.87G [00:17<03:57, 11.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   8%|▌     | 241M/2.87G [00:18<04:15, 10.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   9%|▌     | 252M/2.87G [00:19<03:59, 10.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:   9%|▌     | 262M/2.87G [00:20<03:53, 11.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  10%|▌     | 273M/2.87G [00:21<03:44, 11.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  10%|▌     | 283M/2.87G [00:22<03:37, 11.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  10%|▌     | 294M/2.87G [00:22<03:28, 12.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  11%|▋     | 304M/2.87G [00:23<03:22, 12.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  11%|▋     | 315M/2.87G [00:24<03:20, 12.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  11%|▋     | 325M/2.87G [00:25<03:10, 13.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  12%|▋     | 336M/2.87G [00:25<03:03, 13.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  12%|▋     | 346M/2.87G [00:26<03:15, 12.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  12%|▋     | 357M/2.87G [00:27<03:22, 12.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  13%|▊     | 367M/2.87G [00:28<03:20, 12.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  13%|▊     | 377M/2.87G [00:29<03:10, 13.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  14%|▊     | 388M/2.87G [00:30<03:09, 13.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  14%|▊     | 398M/2.87G [00:30<02:59, 13.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  14%|▊     | 409M/2.87G [00:31<03:00, 13.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  15%|▉     | 419M/2.87G [00:32<02:50, 14.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  15%|▉     | 430M/2.87G [00:32<02:39, 15.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  15%|▉     | 440M/2.87G [00:33<02:38, 15.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  16%|▉     | 451M/2.87G [00:34<02:35, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  16%|▉     | 461M/2.87G [00:34<02:35, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  16%|▉     | 472M/2.87G [00:35<02:48, 14.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  17%|█     | 482M/2.87G [00:36<02:41, 14.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  17%|█     | 493M/2.87G [00:37<02:43, 14.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  18%|█     | 503M/2.87G [00:38<02:59, 13.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  18%|█     | 514M/2.87G [00:38<02:53, 13.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  18%|█     | 524M/2.87G [00:39<02:43, 14.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  19%|█     | 535M/2.87G [00:40<02:39, 14.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  19%|█▏    | 545M/2.87G [00:40<02:34, 15.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  19%|█▏    | 556M/2.87G [00:41<02:32, 15.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  20%|█▏    | 566M/2.87G [00:42<02:34, 14.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  20%|█▏    | 577M/2.87G [00:42<02:31, 15.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  20%|█▏    | 587M/2.87G [00:43<02:24, 15.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  21%|█▎    | 598M/2.87G [00:44<02:20, 16.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  21%|█▎    | 608M/2.87G [00:44<02:18, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  22%|█▎    | 619M/2.87G [00:45<02:24, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  22%|█▎    | 629M/2.87G [00:45<02:16, 16.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  22%|█▎    | 640M/2.87G [00:46<02:17, 16.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  23%|█▎    | 650M/2.87G [00:47<02:19, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  23%|█▍    | 661M/2.87G [00:48<02:32, 14.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  23%|█▍    | 671M/2.87G [00:48<02:24, 15.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  24%|█▍    | 682M/2.87G [00:52<05:22, 6.77MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  24%|█▍    | 692M/2.87G [00:53<04:54, 7.38MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  25%|█▍    | 703M/2.87G [00:54<04:22, 8.24MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  25%|█▍    | 713M/2.87G [00:55<03:56, 9.10MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  25%|█▌    | 724M/2.87G [00:59<07:14, 4.93MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  26%|█▌    | 734M/2.87G [01:00<06:16, 5.66MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  26%|█▌    | 744M/2.87G [01:02<06:02, 5.85MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  26%|█▌    | 755M/2.87G [01:03<04:56, 7.13MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  27%|█▌    | 765M/2.87G [01:03<04:00, 8.73MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  27%|█▌    | 776M/2.87G [01:04<03:30, 9.93MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  27%|█▋    | 786M/2.87G [01:05<03:03, 11.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  28%|█▋    | 797M/2.87G [01:05<02:45, 12.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  28%|█▋    | 807M/2.87G [01:06<02:36, 13.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  29%|█▋    | 818M/2.87G [01:07<02:25, 14.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  29%|█▋    | 828M/2.87G [01:07<02:18, 14.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  29%|█▊    | 839M/2.87G [01:08<02:12, 15.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  30%|█▊    | 849M/2.87G [01:09<02:09, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  30%|█▊    | 860M/2.87G [01:09<02:20, 14.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  30%|█▊    | 870M/2.87G [01:10<02:18, 14.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  31%|█▊    | 881M/2.87G [01:11<02:27, 13.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  31%|█▊    | 891M/2.87G [01:12<02:30, 13.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  31%|█▉    | 902M/2.87G [01:13<02:30, 13.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  32%|█▉    | 912M/2.87G [01:13<02:26, 13.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  32%|█▉    | 923M/2.87G [01:14<02:28, 13.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  33%|█▉    | 933M/2.87G [01:15<02:43, 11.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  33%|█▉    | 944M/2.87G [01:16<02:33, 12.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  33%|█▉    | 954M/2.87G [01:17<02:25, 13.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  34%|██    | 965M/2.87G [01:17<02:20, 13.5MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  34%|██    | 975M/2.87G [01:18<02:23, 13.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  34%|██    | 986M/2.87G [01:19<02:26, 12.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  35%|██    | 996M/2.87G [01:20<02:25, 12.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  35%|█▊   | 1.01G/2.87G [01:21<02:37, 11.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  35%|█▊   | 1.02G/2.87G [01:22<02:39, 11.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  36%|█▊   | 1.03G/2.87G [01:23<02:39, 11.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  36%|█▊   | 1.04G/2.87G [01:24<02:39, 11.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  37%|█▊   | 1.05G/2.87G [01:25<02:35, 11.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  37%|█▊   | 1.06G/2.87G [01:25<02:28, 12.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  37%|█▊   | 1.07G/2.87G [01:26<02:26, 12.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  38%|█▉   | 1.08G/2.87G [01:27<02:19, 12.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  38%|█▉   | 1.09G/2.87G [01:28<02:15, 13.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  38%|█▉   | 1.10G/2.87G [01:29<02:11, 13.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  39%|█▉   | 1.11G/2.87G [01:29<02:06, 13.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  39%|█▉   | 1.12G/2.87G [01:30<02:04, 14.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  40%|█▉   | 1.13G/2.87G [01:31<02:03, 14.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  40%|█▉   | 1.14G/2.87G [01:31<01:59, 14.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  40%|██   | 1.15G/2.87G [01:32<02:02, 14.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  41%|██   | 1.16G/2.87G [01:33<02:20, 12.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  41%|██   | 1.17G/2.87G [01:34<02:16, 12.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  41%|██   | 1.18G/2.87G [01:35<02:10, 12.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  42%|██   | 1.20G/2.87G [01:36<02:00, 13.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  42%|██   | 1.21G/2.87G [01:36<01:56, 14.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  42%|██   | 1.22G/2.87G [01:37<01:50, 14.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  43%|██▏  | 1.23G/2.87G [01:38<01:54, 14.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  43%|██▏  | 1.24G/2.87G [01:39<02:01, 13.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  44%|██▏  | 1.25G/2.87G [01:39<01:58, 13.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  44%|██▏  | 1.26G/2.87G [01:40<01:51, 14.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  44%|██▏  | 1.27G/2.87G [01:41<01:50, 14.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  45%|██▏  | 1.28G/2.87G [01:41<01:44, 15.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  45%|██▏  | 1.29G/2.87G [01:42<01:39, 15.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  45%|██▎  | 1.30G/2.87G [01:43<01:41, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  46%|██▎  | 1.31G/2.87G [01:43<01:39, 15.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  46%|██▎  | 1.32G/2.87G [01:44<01:37, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  46%|██▎  | 1.33G/2.87G [01:45<01:42, 15.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  47%|██▎  | 1.34G/2.87G [01:45<01:38, 15.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  47%|██▎  | 1.35G/2.87G [01:46<01:40, 15.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  48%|██▍  | 1.36G/2.87G [01:47<01:55, 13.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  48%|██▍  | 1.37G/2.87G [01:48<01:53, 13.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  48%|██▍  | 1.38G/2.87G [01:48<01:46, 13.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  49%|██▍  | 1.39G/2.87G [01:49<01:41, 14.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  49%|██▍  | 1.41G/2.87G [01:50<01:50, 13.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  49%|██▍  | 1.42G/2.87G [01:51<01:52, 12.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  50%|██▍  | 1.43G/2.87G [01:52<01:47, 13.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  50%|██▌  | 1.44G/2.87G [01:52<01:43, 13.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  50%|██▌  | 1.45G/2.87G [01:53<01:35, 14.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  51%|██▌  | 1.46G/2.87G [01:54<01:31, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  51%|██▌  | 1.47G/2.87G [01:54<01:28, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  52%|██▌  | 1.48G/2.87G [01:55<01:24, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  52%|██▌  | 1.49G/2.87G [01:55<01:24, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  52%|██▌  | 1.50G/2.87G [01:56<01:20, 17.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  53%|██▋  | 1.51G/2.87G [01:57<01:20, 16.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  53%|██▋  | 1.52G/2.87G [01:57<01:17, 17.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  53%|██▋  | 1.53G/2.87G [01:58<01:19, 16.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  54%|██▋  | 1.54G/2.87G [01:58<01:19, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  54%|██▋  | 1.55G/2.87G [01:59<01:17, 16.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  54%|██▋  | 1.56G/2.87G [02:00<01:15, 17.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  55%|██▋  | 1.57G/2.87G [02:00<01:14, 17.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  55%|██▊  | 1.58G/2.87G [02:01<01:22, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  56%|██▊  | 1.59G/2.87G [02:02<01:20, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  56%|██▊  | 1.60G/2.87G [02:02<01:17, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  56%|██▊  | 1.61G/2.87G [02:03<01:15, 16.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  57%|██▊  | 1.63G/2.87G [02:04<01:14, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  57%|██▊  | 1.64G/2.87G [02:04<01:15, 16.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  57%|██▊  | 1.65G/2.87G [02:05<01:16, 16.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  58%|██▉  | 1.66G/2.87G [02:06<01:14, 16.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  58%|██▉  | 1.67G/2.87G [02:06<01:11, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  59%|██▉  | 1.68G/2.87G [02:07<01:10, 16.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  59%|██▉  | 1.69G/2.87G [02:07<01:10, 16.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  59%|██▉  | 1.70G/2.87G [02:08<01:08, 17.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  60%|██▉  | 1.71G/2.87G [02:09<01:08, 16.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  60%|██▉  | 1.72G/2.87G [02:09<01:08, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  60%|███  | 1.73G/2.87G [02:10<01:06, 17.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  61%|███  | 1.74G/2.87G [02:10<01:04, 17.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  61%|███  | 1.75G/2.87G [02:11<01:04, 17.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  61%|███  | 1.76G/2.87G [02:12<01:03, 17.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  62%|███  | 1.77G/2.87G [02:12<01:05, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  62%|███  | 1.78G/2.87G [02:13<01:08, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  63%|███▏ | 1.79G/2.87G [02:14<01:05, 16.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  63%|███▏ | 1.80G/2.87G [02:14<01:03, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  63%|███▏ | 1.81G/2.87G [02:15<01:04, 16.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  64%|███▏ | 1.82G/2.87G [02:15<01:02, 16.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  64%|███▏ | 1.84G/2.87G [02:16<01:01, 16.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  64%|███▏ | 1.85G/2.87G [02:17<01:02, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  65%|███▏ | 1.86G/2.87G [02:18<01:09, 14.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  65%|███▎ | 1.87G/2.87G [02:18<01:06, 15.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  65%|███▎ | 1.88G/2.87G [02:19<01:05, 15.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  66%|███▎ | 1.89G/2.87G [02:20<01:02, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  66%|███▎ | 1.90G/2.87G [02:20<01:01, 15.7MB/s]\u001b[A\n",
      "Fetching 1 files:   0%|                                   | 0/1 [02:22<?, ?it/s]\u001b[A\n",
      "\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  67%|███▎ | 1.92G/2.87G [02:22<01:00, 15.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  67%|███▎ | 1.93G/2.87G [02:22<01:01, 15.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  68%|███▍ | 1.94G/2.87G [02:23<00:58, 15.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  68%|███▍ | 1.95G/2.87G [02:24<00:58, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  68%|███▍ | 1.96G/2.87G [02:24<00:59, 15.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  69%|███▍ | 1.97G/2.87G [02:25<01:00, 14.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  69%|███▍ | 1.98G/2.87G [02:26<00:56, 15.8MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  69%|███▍ | 1.99G/2.87G [02:26<00:56, 15.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  70%|███▍ | 2.00G/2.87G [02:27<00:58, 14.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  70%|███▌ | 2.01G/2.87G [02:28<00:55, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  71%|███▌ | 2.02G/2.87G [02:28<00:53, 15.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  71%|███▌ | 2.03G/2.87G [02:29<00:51, 16.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  71%|███▌ | 2.04G/2.87G [02:30<00:51, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  72%|███▌ | 2.06G/2.87G [02:31<00:54, 15.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  72%|███▌ | 2.07G/2.87G [02:31<00:51, 15.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  72%|███▌ | 2.08G/2.87G [02:32<00:49, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  73%|███▋ | 2.09G/2.87G [02:32<00:48, 16.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  73%|███▋ | 2.10G/2.87G [02:33<00:47, 16.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  74%|███▋ | 2.11G/2.87G [02:34<00:47, 16.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  74%|███▋ | 2.12G/2.87G [02:35<00:51, 14.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  74%|███▋ | 2.13G/2.87G [02:35<00:47, 15.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  75%|███▋ | 2.14G/2.87G [02:36<00:48, 14.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  75%|███▋ | 2.15G/2.87G [02:37<00:47, 15.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  75%|███▊ | 2.16G/2.87G [02:37<00:45, 15.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  76%|███▊ | 2.17G/2.87G [02:38<00:44, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  76%|███▊ | 2.18G/2.87G [02:39<00:43, 15.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  76%|███▊ | 2.19G/2.87G [02:39<00:44, 15.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  77%|███▊ | 2.20G/2.87G [02:40<00:42, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  77%|███▊ | 2.21G/2.87G [02:41<00:41, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  78%|███▉ | 2.22G/2.87G [02:41<00:40, 15.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  78%|███▉ | 2.23G/2.87G [02:42<00:39, 16.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  78%|███▉ | 2.24G/2.87G [02:43<00:38, 16.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  79%|███▉ | 2.25G/2.87G [02:43<00:37, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  79%|███▉ | 2.26G/2.87G [02:44<00:36, 16.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  79%|███▉ | 2.28G/2.87G [02:46<01:02, 9.47MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  80%|███▉ | 2.29G/2.87G [02:47<00:57, 10.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  80%|████ | 2.30G/2.87G [02:48<00:51, 11.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  80%|████ | 2.31G/2.87G [02:48<00:46, 12.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  81%|████ | 2.32G/2.87G [02:49<00:42, 12.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  81%|████ | 2.33G/2.87G [02:50<00:39, 13.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  82%|████ | 2.34G/2.87G [02:50<00:36, 14.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  82%|████ | 2.35G/2.87G [02:51<00:35, 14.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  82%|████ | 2.36G/2.87G [02:52<00:33, 15.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  83%|████▏| 2.37G/2.87G [02:52<00:32, 15.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  83%|████▏| 2.38G/2.87G [02:53<00:32, 14.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  83%|████▏| 2.39G/2.87G [02:54<00:30, 15.4MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  84%|████▏| 2.40G/2.87G [02:54<00:29, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  84%|████▏| 2.41G/2.87G [02:55<00:28, 15.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  84%|████▏| 2.42G/2.87G [02:56<00:27, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  85%|████▏| 2.43G/2.87G [02:56<00:29, 14.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  85%|████▎| 2.44G/2.87G [02:57<00:27, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  86%|████▎| 2.45G/2.87G [02:58<00:25, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  86%|████▎| 2.46G/2.87G [02:58<00:25, 16.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  86%|████▎| 2.47G/2.87G [02:59<00:24, 15.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  87%|████▎| 2.49G/2.87G [03:00<00:24, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  87%|████▎| 2.50G/2.87G [03:00<00:23, 15.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  87%|████▎| 2.51G/2.87G [03:01<00:23, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  88%|████▍| 2.52G/2.87G [03:02<00:21, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  88%|████▍| 2.53G/2.87G [03:02<00:20, 16.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  89%|████▍| 2.54G/2.87G [03:03<00:19, 16.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  89%|████▍| 2.55G/2.87G [03:03<00:18, 17.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  89%|████▍| 2.56G/2.87G [03:04<00:17, 17.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  90%|████▍| 2.57G/2.87G [03:05<00:18, 16.3MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  90%|████▍| 2.58G/2.87G [03:05<00:17, 16.1MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  90%|████▌| 2.59G/2.87G [03:06<00:18, 14.7MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  91%|████▌| 2.60G/2.87G [03:07<00:17, 15.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  91%|████▌| 2.61G/2.87G [03:07<00:15, 16.1MB/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                   initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mload_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt)\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mload_llm\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_llm\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     llm \u001b[38;5;241m=\u001b[39m \u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTheBloke/Llama-2-7B-Chat-GGML\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/langchain_core/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/pydantic/main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/langchain/llms/ctransformers.py:73\u001b[0m, in \u001b[0;36mCTransformers.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import `ctransformers` package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install ctransformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 73\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/ctransformers/hub.py:168\u001b[0m, in \u001b[0;36mAutoModelForCausalLM.from_pretrained\u001b[0;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_find_model_path_from_dir(\n\u001b[1;32m    165\u001b[0m         model_path_or_repo_id, model_file\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 168\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_model_path_from_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM(\n\u001b[1;32m    176\u001b[0m     model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[1;32m    177\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[1;32m    178\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    179\u001b[0m     lib\u001b[38;5;241m=\u001b[39mlib,\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hf:\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/ctransformers/hub.py:203\u001b[0m, in \u001b[0;36mAutoModelForCausalLM._find_model_path_from_repo\u001b[0;34m(cls, repo_id, filename, local_files_only, revision)\u001b[0m\n\u001b[1;32m    198\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_find_model_file_from_repo(\n\u001b[1;32m    199\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    200\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m allow_patterns \u001b[38;5;241m=\u001b[39m filename \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 203\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_find_model_path_from_dir(path, filename\u001b[38;5;241m=\u001b[39mfilename)\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/huggingface_hub/_snapshot_download.py:238\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, endpoint)\u001b[0m\n\u001b[1;32m    236\u001b[0m         _inner_hf_hub_download(file)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFetching \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(local_dir))\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tqdm_class(ex\u001b[38;5;241m.\u001b[39mmap(fn, \u001b[38;5;241m*\u001b[39miterables, chunksize\u001b[38;5;241m=\u001b[39mchunksize), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/concurrent/futures/_base.py:644\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/concurrent/futures/thread.py:236\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 236\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/QnA/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llm = load_llm()\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kwJ1-Hkq3ioL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  98%|████▉| 2.81G/2.87G [03:26<00:05, 11.0MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  98%|████▉| 2.82G/2.87G [03:27<00:03, 12.5MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  99%|████▉| 2.83G/2.87G [03:27<00:02, 13.6MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  99%|████▉| 2.84G/2.87G [03:28<00:01, 13.8MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin:  99%|████▉| 2.85G/2.87G [03:29<00:01, 14.2MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin: 100%|████▉| 2.86G/2.87G [03:29<00:00, 14.9MB/s]\u001b[A\n",
      "llama-2-7b-chat.ggmlv3.q2_K.bin: 100%|█████| 2.87G/2.87G [03:30<00:00, 13.6MB/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "def getInfo(question: str, top_k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the relevant plot for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): What do we want to know?\n",
    "        top_k (int): Top K results to return\n",
    "\n",
    "    Returns:\n",
    "        context (List[str]):\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_query =  sentencetf.encode(question)  # generate embeddings for the question\n",
    "\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=encoded_query,\n",
    "            limit=top_k,\n",
    "        )  # search qdrant collection for context passage with the answer\n",
    "\n",
    "        context = [\n",
    "    {\n",
    "        'name': x.payload.get('name', ''),\n",
    "        'category': x.payload.get('category', ''),\n",
    "        'sub_category': x.payload.get('sub_category', ''),\n",
    "        'brand': x.payload.get('brand', ''),\n",
    "        'sale_price': x.payload.get('sale_price', 0.0),\n",
    "        'market_price': x.payload.get('market_price', 0.0),\n",
    "        'type': x.payload.get('type', ''),\n",
    "        'rating': x.payload.get('rating', float('nan'))\n",
    "    } for x in result\n",
    "]\n",
    "        prompt = PromptTemplate.from_template(\n",
    "        \"question is={question}. you should answer from: {docs}\"\n",
    ")\n",
    "\n",
    "        # Chain\n",
    "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        answer = llm_chain(context)\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puIWQFmsoTIa",
    "outputId": "256d56fa-22a1-4c2b-87ac-e04e12519809"
   },
   "outputs": [],
   "source": [
    "getInfo('what is the price of chia seeds?', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHUBatQH1nyl"
   },
   "outputs": [],
   "source": [
    "# custom_prompt_template = \"\"\"Use the following pieces of information to answer the user’s question.\n",
    "# If you don’t know the answer, just say that you don’t know, don’t try to make up an answer.\n",
    "\n",
    "# Context: {context}\n",
    "# Question: {question}\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = PromptTemplate(template=custom_prompt_template,\n",
    "#                             input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWdGJvaf2VRi"
   },
   "outputs": [],
   "source": [
    "# response('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGWbv5GF1oFy"
   },
   "outputs": [],
   "source": [
    "# class ConversationManager:\n",
    "#     def __init__(self):\n",
    "#         self.context = \"\"  # Initialize empty context for the conversation\n",
    "\n",
    "#     def update_context(self, new_context):\n",
    "#         self.context += \" \" + new_context  # Append new context to the existing context\n",
    "\n",
    "#     def get_response(self, query):\n",
    "#         self.update_context(query)  # Add the user's query to the conversation context\n",
    "#         response = qa_bot_qdrant_response(query)\n",
    "#         return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMEdsrDZ6Dbc"
   },
   "outputs": [],
   "source": [
    "# conversation_manager = ConversationManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWtqQ3vd-YQX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LO_MFAw1oMF"
   },
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     user_input = input(\"User: \")\n",
    "#     if user_input.lower() == 'exit':\n",
    "#         print(\"Bot: Goodbye!\")\n",
    "#         break\n",
    "#     response = conversation_manager.get_response(user_input)\n",
    "#     print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCFoX__uflvh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJj2K_Esfl0J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xN6tJuqs-NQM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhXOCpiV-NYu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvzIFK2j-NgK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1zmuuz--Nmv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QnA",
   "language": "python",
   "name": "qna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0aac17a0cae54c9db845ff5de218f9ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f12c9e61304449da5682ed238e5daac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd2f061e1d8743698d0c1f95514ca516",
      "placeholder": "​",
      "style": "IPY_MODEL_6e0d1e97b73c4d55aeab511820cd8f0b",
      "value": "Fetching 1 files: 100%"
     }
    },
    "1208e34b755c452bad18f4c75e539d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1305681bdaf54a9980d83b741c6f80ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c68cf2ce64d4c46ae4099d5be042868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc4ad43b92b54945b680eee32f3892fd",
      "placeholder": "​",
      "style": "IPY_MODEL_46dd3e5fb01746e69e4b31fa9c16ec92",
      "value": "Fetching 1 files: 100%"
     }
    },
    "248ed5b0fc2e4a79b16077ebd9ff8271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2496104b44804729890b9bb8e97ecb8f",
       "IPY_MODEL_b1ca4ae79288443781ab656986cb07b4",
       "IPY_MODEL_6487943299394b3c8963ef2bb09b5429"
      ],
      "layout": "IPY_MODEL_1305681bdaf54a9980d83b741c6f80ca"
     }
    },
    "2496104b44804729890b9bb8e97ecb8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83a023425d2047eba31d6e891f7bb67d",
      "placeholder": "​",
      "style": "IPY_MODEL_9e8a4ea798e04d78bd2b8eaed2d5768b",
      "value": "  0%"
     }
    },
    "31792a1173b84e44ab6354cb90393254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34fb99e015e447b7a620c31f44be09e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c68cf2ce64d4c46ae4099d5be042868",
       "IPY_MODEL_cbbccd3f802f40ff80efb03b95633e43",
       "IPY_MODEL_d1813de27ff64e0eabd2669e9a439e55"
      ],
      "layout": "IPY_MODEL_df87ce4831d548b1905fa4adbcc5a60e"
     }
    },
    "35a3b06ff02b4284ab83bd1d35295b1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46dd3e5fb01746e69e4b31fa9c16ec92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53141e486281440a8f88794f289f3f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6487943299394b3c8963ef2bb09b5429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31792a1173b84e44ab6354cb90393254",
      "placeholder": "​",
      "style": "IPY_MODEL_8a38a7e2a6814e9e9839f1c87f05b8b4",
      "value": " 0/14 [00:00&lt;?, ?it/s]"
     }
    },
    "6e0d1e97b73c4d55aeab511820cd8f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81913db5c5434f82aaf31e3a66538684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f12c9e61304449da5682ed238e5daac",
       "IPY_MODEL_96ddfebe6180454e96973604e3671f0f",
       "IPY_MODEL_8f7edb1fd1254ac88ab2f40227f623bc"
      ],
      "layout": "IPY_MODEL_88ef181331764920938918ada29925ec"
     }
    },
    "83a023425d2047eba31d6e891f7bb67d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ef181331764920938918ada29925ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a38a7e2a6814e9e9839f1c87f05b8b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f7edb1fd1254ac88ab2f40227f623bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92e47a29f21e44409947450846be8c8b",
      "placeholder": "​",
      "style": "IPY_MODEL_53141e486281440a8f88794f289f3f38",
      "value": " 1/1 [00:00&lt;00:00, 56.80it/s]"
     }
    },
    "92e47a29f21e44409947450846be8c8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96ddfebe6180454e96973604e3671f0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0aac17a0cae54c9db845ff5de218f9ab",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35a3b06ff02b4284ab83bd1d35295b1f",
      "value": 1
     }
    },
    "9e8a4ea798e04d78bd2b8eaed2d5768b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9f6bf5f2ec84833961ebe432c2a47ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1ca4ae79288443781ab656986cb07b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec72171ba64940d4b3de4fa7fdc4191d",
      "max": 14,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9e7108c96d04230a92208d5a9b01498",
      "value": 0
     }
    },
    "b49e3abf561246d380a3458e5f47933a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd2f061e1d8743698d0c1f95514ca516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8d6fc0406fe4258a5a28cd26875d432": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e7108c96d04230a92208d5a9b01498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbbccd3f802f40ff80efb03b95633e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b49e3abf561246d380a3458e5f47933a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1208e34b755c452bad18f4c75e539d53",
      "value": 1
     }
    },
    "d1813de27ff64e0eabd2669e9a439e55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8d6fc0406fe4258a5a28cd26875d432",
      "placeholder": "​",
      "style": "IPY_MODEL_a9f6bf5f2ec84833961ebe432c2a47ad",
      "value": " 1/1 [00:00&lt;00:00, 68.49it/s]"
     }
    },
    "df87ce4831d548b1905fa4adbcc5a60e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec72171ba64940d4b3de4fa7fdc4191d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc4ad43b92b54945b680eee32f3892fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
